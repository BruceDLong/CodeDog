// EarleyParser.Lib.dog
///////////////////////////
/*
The easiest way you use this is to autogenerate rules and parser functions with stringStructs.

To use it manually:
        1. Create a parser:           me EParser: parser
        2. Initialize your grammar:   parser.populateGrammar()
        3. Register the start symbol (an int from your grammar) and the string or stream to parse:
                parser.initParseFromString(streamName, startSymbol, textIn)
          OR    parser.initParseFromStream(startSymbol, IOBufferIn)
        4. Run the parse:             parser.doParse()
        5. Check for parse errors:    if(parser.doesParseHaveError()){print("Parse Error:" + parser.errorMesg)}
        6. if there are no errors make sure the parse is resolved:
            Either have it resolved during parseing, which is slower but can enable stream parsing
            OR call topDownResolve():        our stateRec: topItem <- parser.topDownResolve(parser.lastTopLevelItem, "")
        7. Extract the parse to your data structure.
            Stringstructs can automatically write a function to do this:
               Allocate(structToFill)
               parser.Extract_<CLASSNAME>_to_<CLASSNAME>(topItem, structToFill)
            It is also possible to have the extraction done while parsing is happening for a streaming parse.

        For a non-streaming parse:
            * Initialize with parser.initParseFromString(streamName, startSymbol, textIn).
            * Call topDownResolve after the parse (because it is faster to do so).
            * Extract the parse after resolve.

        For a streaming parse:
            * Initialize with parser.initParseFromStream(startSymbol, IOBufferIn). // The buffer need not be full
            * call setStreamingMode(true) to enable blocking on the buffer, in-parse resolving and signaling for an Extract thread.
            * Use a thread to put data into the buffer.
            * Make a thread to extract the data as it is parsed.

        Stringstructs will generate code to do the above:
            * For non-streaming parse it generates the parser member function:
                our myStruct: Parse_myStruct(string textIn)

            * For streaming parses it generates a class:
                struct Threaded_infonParseAndExtractor

NOTE:
    The Earley parser by default resolves 'nullable' productions by going into them.
    * The reason for this choice is that extracting the data becomes easier to automate.
    * However, this is not as efficient, and a technique described in "Practical Earley Parsing (Aycock 2002)"
    * is available: After populating your grammar (i.e, after calling populateGrammar()), call setQuickParse(true)
    * This call will predetermine which productions are nullable and set a flag to modify the algorithm.

 */

featuresNeeded = [IOBuffer, Threads]

struct production{
    flag: isTerm
    mode[parseSEQ, parseALT, parseREP, parseOPT, parseAUTO]: prodType
    me string: constStr
    me int: myIndex
    me int: lvlsToBackApprove
    me List<me int>: items
    flag: isNullable
    flag: nullabilityCalced
    me bool: isP_nullable() <- { // for analysis, not for parsing
        return(isNullable or myIndex==EParser.wsc or myIndex==EParser.ws)
    }
    me string: nameToStr(their List<me string>: rnames) <- {
        me string: retval
        if(isTerm){retval <- constStr}
        else if(myIndex < rnames.size()){retval <- rnames[myIndex]}
        else{retval<-"UNKNOWN"}
        if(isTerm){retval <- "'"+retval+"'"}
        return(retval)
    }
    me string: toStr(me int64: seqPos, me int64: originPos, me int64: crntPos, their List<me string>: rnames) <- {
        me int: ProdType <- prodType
        me string: S <- ""
        me string: ProdStr <- ""
        S <+- "["
        if     (ProdType==parseALT) {ProdStr<-"ALT: "}
        else if(ProdType==parseAUTO){ProdStr<-"Aut: "}
        else if(ProdType==parseSEQ) {ProdStr<-"SEQ: "}
        else if(ProdType==parseREP) {ProdStr<-"REP: "}
        S <+- ProdStr
        S <+- toString(originPos) + ".." + toString(crntPos) + ": "   // Show origin slot
        if(isTerm){
            if(seqPos==0) {S <+- " > "}
            S <+- '"' + constStr + '"'
            if(seqPos>0) {S <+- " > "}
        } else {
            if(ProdType==parseALT and seqPos==0) {S <+- " > "}
            withEach p in items {
                if(ProdType == parseSEQ and p_key == seqPos){ S <+- " > "}
                if(p_key!=0){
                    if(ProdType==parseALT){
                        if(p_key == seqPos){ S <+- " > "}
                        S <+- "| "
                    }
                }
                if(ProdType==parseREP and p_key>0){S <+- toString(p) + " "}
                else {S <+- rnames[p] + " "}
            }
            if(ProdType==parseREP){ S <+- '(Len:%i`seqPos`)'}
            else {if (((p_key == seqPos and ProdType == parseSEQ) or (ProdType==parseALT and seqPos>0))) {S <+- " > "}}
        }
        if(isNullable){S<+-" -NBL"}
        S <+- "] "
        return(S)
    }
}

struct pedigree{
    our stateRec: pred
    our stateRec: cause
    me int: productionID
}

struct stateRec{
    me int: productionID
    me int64: SeqPosition
    me int64: originPos
    me int64: crntPos
    me List<me pedigree>: pedigrees
    our stateRec: next
    our stateRec: child
    flag: pathNotChosen
    flag: resolved

    // The following flags are used in streaming mode:
    flag: nextIsFilled   // Used when streaming
    flag: childIsFilled  // Used when streaming
    flag: failed         // True if this path has failed in streaming mode.
    flag: parseDone      // This branch has no more work to be done.
    me int: altCount     // For ALTs, number of failed branches.
    me string: stringify(their EParser: EP) <- {
        me string: S <- ""
        their production: prod <- EP.grammar[productionID]
        S <+- prod.toStr(SeqPosition, originPos, crntPos, EP.rnames)
        if(prod.isTerm){
            S <+- "='"
            withEach idx in RANGE(originPos..crntPos){S<+- EP.getCharAt(idx)}
            S <+- "'"
        }
        if(resolved){S<+-"-R"}
       return(S)
    }

flag: MARKer1  // Use these to mark staterecs in grapher
flag: MARKer2  // They are for debugging and can be removed
}

struct stateSets{
    me List<our stateRec>: stateRecs
}

struct productionChainItem{
    me int: prodID
    me int: index
}

struct EParser{
    their strBuf: streamToParse
    me int: startProduction
    me List<me stateSets>: SSets
    me List<me production>: grammar
    me bool: parseFound
    our stateRec: lastTopLevelItem
    our stateRec: topParseNode
    me int64: highestSlotSoFar
    me string: errorMesg
    me List<me string>: rnames

    me bool: streamingMode
    me bool: parseTreeFinished
    me Mutex: streamingSRecNextMutex
    me SyncLock: streamingSRecNextLock
    me Mutex: streamingSRecChildMutex
    me SyncLock: streamingSRecChildLock

    me bool: doQuickParse
    void: setQuickParse(me bool: doQuick) <- {
        doQuickParse <- doQuick
        if(doQuickParse){preCalcNullability()}
    }


    me char: getCharAt(me int64: pos) <- {
        me char: ch <- streamToParse.at(pos)
        topOffSSets()
        return(ch)
    }
    our strBufItr: getItrAt(me int64: pos) <- {
        our strBufItr: bufItr <- streamToParse.getItrAt(pos)
        topOffSSets()
        return(bufItr)
    }

    void: clearGrammar() <- {grammar.clear() rnames.clear()}
    void: addTerminalProd(me string: name, me int: ProdType, me string: s) <- {
        me production: P
        P.prodType  <- ProdType
        P.isTerm    <- true
        P.constStr  <- s
        P.myIndex   <- rnames.size()
        P.isNullable<- false //(ProdType==parseAUTO and (name=="ws" or name=="wsc"))
        P.nullabilityCalced <- true
        grammar.append(P)
        rnames.append(name)
    }
    void: addNon_TermProd(me string: name, me int: ProdType, me List<me int>: terms) <- {
        me production: prod
        prod.prodType   <- ProdType
        prod.items      <- terms
        prod.myIndex    <- rnames.size()
        if(doQuickParse){
            if(prod.prodType==parseREP and prod.items[1]==0){prod.isNullable<-true; prod.nullabilityCalced <- true}
            else if(prod.prodType==parseSEQ and prod.items.size()==0){prod.isNullable<-true; prod.nullabilityCalced <- true}
            else if(prod.prodType==parseALT and prod.items.size()==0){prod.isNullable<-true; prod.nullabilityCalced <- true}
        }
        grammar.append(prod)
        rnames.append(name)
    }

    me bool: isNullableSet(their production: prod) <- {
        // This function must be called with completed grammar
        // and on the simplest productions first to avoid hanging
        me bool: retVal
        if(prod.nullabilityCalced){return(prod.isNullable)}
        if(prod.isTerm){
  //          if(prod.prodType==parseAUTO and (name=="ws" or name=="wsc")){retVal <- true}
        } else {
            if(prod.prodType==parseSEQ){
                retVal<-true
                withEach item in prod.items{
                    if(!isNullableSet(grammar[item])){retVal<-false; break()}
                }
            } else if(prod.prodType==parseALT){
                retVal<-false
                withEach item in prod.items{
                    if(isNullableSet(grammar[item])){retVal<-true; break()}
                }
            } else if(prod.prodType==parseREP){
                if(prod.items[1]==0 or isNullableSet(grammar[prod.items[0]])){retVal <- true}
            }
        }
        prod.isNullable <- retVal
        prod.nullabilityCalced<-true
        return(retVal)
    }
    void: preCalcNullability() <- {
        // This assumes very simple nullable productions are already marked
        // If you used add*Prod() to add them, they are.
        withEach prod1 in grammar{
            if(prod1.nullabilityCalced){continue()}
            if(!prod1.isTerm){
                if(prod1.prodType==parseSEQ){
                    me bool: checkable <-true
                    withEach item in prod1.items{
                        if(!grammar[item].nullabilityCalced){checkable<-false}
                    }
                    if(checkable){isNullableSet(prod1)}
                }else if(prod1.prodType==parseREP){
                    if(grammar[prod1.items[0]].nullabilityCalced){
                        isNullableSet(prod1)
                    }
                }
            }
        }
        withEach prod2 in grammar{
            isNullableSet(prod2)
        }
    }

    me int: incProductionCount(me int: prodID, their Map<me int, me int>: prod2TimesUsed) <- {
        itr Map<me int, me int>: it <- prod2TimesUsed.find(prodID)
        if(it == prod2TimesUsed.end()){
            prod2TimesUsed[prodID]<-1
        } else {prod2TimesUsed[prodID] <+- 1}
        return(prod2TimesUsed[prodID])
    }

    me bool: calcStreamPointsFromProd(me int: prodID, their Map<me int, me int>: prod2TimesUsed, me int:level) <- {
        their production: prod<-grammar[prodID]
        if(prod.isTerm){
            //log(indentedStr("",level,0)+":"+prod.nameToStr(rnames)+" "+toString(level))
            me int: timesUsed <-  incProductionCount(prodID, prod2TimesUsed)
            if(timesUsed==1){prod.lvlsToBackApprove <- level} else {prod.lvlsToBackApprove <- 1} // min(prod.lvlsToBackApprove, level)}
        } else{
            //log(indentedStr("",level,0)+":"+prod.nameToStr(rnames))
            me int: timesUsed <-  incProductionCount(prodID, prod2TimesUsed)
            if(timesUsed==1){prod.lvlsToBackApprove <- 1} else {prod.lvlsToBackApprove <- 1}
            if(timesUsed >1){return(false)}
            if(prod.prodType==parseSEQ){
                withEach p in prod.items{
                    if(calcStreamPointsFromProd(p, prod2TimesUsed, level+1)){return(true)}
                }
            } else if(prod.prodType==parseREP){
                if(calcStreamPointsFromProd(prod.items[0], prod2TimesUsed, level+1)){return(true)}
            } else if(prod.prodType==parseALT){
                withEach p in prod.items{
                    if(calcStreamPointsFromProd(p, prod2TimesUsed, level+1)){return(true)}
                }
            } else {logFatalError("Unexpected productionType:"+toString(prod.prodType))}
        }
        return(false)
    }

    void: preCalcStreamPoints() <- {
        me Map<me int, me int>: prod2TimesUsed
        calcStreamPointsFromProd(infon_str, prod2TimesUsed, 0)
        //withEach prod in prod2TimesUsed{log(toString(prod_key)+"-PROD:"+grammar[prod_key].nameToStr(rnames)+ ": times used:"+toString(prod2TimesUsed[prod_key]) + "  lvlsToBackApprove:"+toString(grammar[prod_key].lvlsToBackApprove))}

    ///    tryToFindAmbiguities(); exit(2)
    }
/*
    me string: stringifyParsePos(their List<productionChainItem>: parsePos) <- {
        me string: S
        me int: count <- 0
        withEach pItem in parsePos{
            their production: prod<-grammar[pItem.prodID]
            if(prod.isTerm){S <+- ":'"+prod.nameToStr(rnames)+"' "}
            else{
                S <+- ":"+prod.nameToStr(rnames)
                if(prod.prodType==parseSEQ){
                    S <+- "$"+toString(pItem.index)
                } else if(prod.prodType==parseALT){
                    S <+- "@"+toString(pItem.index)
                } else{
                    S <+- "&"+toString(pItem.index)
                }
            }
            count <+- 1
        }
        return(S)
    }

    void: goPotentialNextProd(their List<productionChainItem>: parsePos) <- {
        me int: lastItemIdx <- parsePos.size()-1
        their production: crntPred <- grammar[parsePos.last().prodID]
        if(lastItemIdx > 0){
            me int: prevItemIdx <- lastItemIdx-1
            me int: prevProdID  <- parsePos[prevItemIdx].prodID
            me int: prevProdIdx <- parsePos[prevItemIdx].index+1
            their production: prevProd<-grammar[prevProdID]
            me int: maxIdx <- prevProd.items.size()
            if(prevProd.prodType==parseREP){
                if(prevProd.items[2]==0){maxIdx <- 2}
                else{maxIdx <- min(prevProd.items[2], 1)}  // 2
                //log("parseREP:"+toString(prevProdIdx)+" >=  maxIdx:"+toString(maxIdx) + "  in:"+prevProd.nameToStr(rnames))
            }
            if(prevProd.isTerm or prevProdIdx >= maxIdx){
                parsePos[prevItemIdx].index  <- prevProdIdx
                parsePos.popLast()
                goPotentialNextProd(parsePos)
            } else {
                parsePos[prevItemIdx].index  <- prevProdIdx
                if(prevProd.prodType==parseREP){prevProdIdx<-0}
                parsePos[lastItemIdx].prodID <- prevProd.items[prevProdIdx]
                parsePos[lastItemIdx].index  <- 0
            }
        }
        return()
    }

    me string: testForAmbig_simple(their production: prodL, their production: prodR, me string: LPath, me string: RPath) <- {
        //log("######## TESTING:"+prodL.nameToStr(rnames)+"   R:"+prodR.nameToStr(rnames)); log("######## ^^^^^^^:"+LPath+"   R:"+RPath)
        if(prodL.isP_nullable() and prodR.isP_nullable()){
            if((prodL.myIndex==ws or prodL.myIndex==wsc) and (prodR.myIndex==ws or prodR.myIndex==wsc)){
                log("######## Ambiguity-WS L:"+prodL.nameToStr(rnames)+"   R:"+prodR.nameToStr(rnames))
                log("^^^^^^^^ L:"+LPath)
                log("^^^^^^^^ R:"+RPath)
            } else if(prodL.myIndex == prodR.myIndex){
                log("######## Ambiguity L:"+prodL.nameToStr(rnames)+"   R:"+prodR.nameToStr(rnames))
                log("^^^^^^^^ L:"+LPath)
                log("^^^^^^^^ R:"+RPath)
            }
        }
        me string: logNullability <- ""; if(prodR.isP_nullable()){logNullability <- "-N"}
        return(prodR.nameToStr(rnames)+logNullability)
    }
    me string: testForAmbig_wAlts(their production: prodL, their production: prodR, me string: LPath, me string: RPath) <- {
        me string: ret
        ret <+- testForAmbig_simple(prodL, prodR, LPath, RPath)
        if(!prodR.isTerm){
            if(prodR.prodType==parseALT){
                ret <+- "^["
                withEach altID in prodR.items{
                    their production: prodAlt<-grammar[altID]
                    ret <+- testForAmbig_wAlts(prodL, prodAlt, LPath, RPath + "^"+prodAlt.nameToStr(rnames))
                }
                ret <+- "]"
            }else if(prodR.prodType==parseSEQ){
                their production: prodSEQ<-grammar[prodR.items[0]]
                ret <+- "^" + testForAmbig_wAlts(prodL, prodSEQ, LPath, RPath + "^"+prodSEQ.nameToStr(rnames))
            }else if(prodR.prodType==parseREP){
            }
        }
        return(ret)
    }

    void: CheckProdChainForAmbiguity(their List<productionChainItem>: parsePos) <- {
        me int: prodID <- parsePos.last().prodID
        their production: prodL <- grammar[prodID]
        //log("****** CONSIDER:"+prodL.nameToStr(rnames))

        me string: Str
        me int: count <- 0
        me List<productionChainItem>: parsePos2
        withEach pItem in parsePos{
            parsePos2.append(pItem)
            if(count>0){Str <+- "   |"} else{count <- 1}
        }
        if(prodL.isTerm){Str <+- ":'"+prodL.nameToStr(rnames)+"' "}else{Str <+- ":"+prodL.nameToStr(rnames)} Str <+- " --> <"

        me bool: getANext <- true
        me string: sepChar <- ""
        while(getANext){
            goPotentialNextProd(parsePos2)
            their production: prod2 <- grammar[parsePos2[parsePos2.size()-1].prodID]
            if(parsePos2.first().index < grammar[parsePos2.first().prodID].items.size() and (parsePos2.size()>1 or parsePos.size()>1)){
                //log("$$$$$$ CHECKING:"+prodL.nameToStr(rnames)+"   R:"+prod2.nameToStr(rnames)); log("$$$$$$ -------- L:"+stringifyParsePos(parsePos) +"  R:"+ stringifyParsePos(parsePos2))
                Str <+- sepChar
                Str <+- testForAmbig_wAlts(prodL, prod2, stringifyParsePos(parsePos), stringifyParsePos(parsePos2))
                if(!prod2.isP_nullable()){getANext <- false}
                if(getANext){sepChar <- ", "}
            }else{Str <+- " DONE"; getANext <- false}
        }
        Str <+- "> "
        log(Str)
    }

    me bool: constructParseMap(their Map<me int, me int>: prod2TimesUsed, their List<productionChainItem>: parsePos, me int:level) <- {
        me int: prodID <- parsePos.last().prodID
        their production: prod<-grammar[prodID]
        CheckProdChainForAmbiguity(parsePos)
        if(prod.isTerm){
            me int: timesUsed <-  incProductionCount(prodID, prod2TimesUsed)
        } else{
            me int: timesUsed <-  incProductionCount(prodID, prod2TimesUsed)
            if(timesUsed>1){return(false)}
            if(prod.prodType==parseSEQ){
                withEach p in prod.items{
                    me productionChainItem: PCItm; PCItm.prodID <- p;  PCItm.index <- 0;
                    parsePos.append(PCItm)
                      if(constructParseMap(prod2TimesUsed, parsePos, level+1)){parsePos.popLast(); return(true)}
                    parsePos.popLast()
                    parsePos.last().index <+- 1
                }
            } else if(prod.prodType==parseREP){
                me productionChainItem: PCItm; PCItm.prodID <- prod.items[0];  PCItm.index <- 0;
                parsePos.append(PCItm)
                  if(constructParseMap(prod2TimesUsed, parsePos, level+1)){parsePos.popLast(); return(true)}
                  parsePos.popLast()
                if(prod.items[2]>1 or prod.items[2]==0){ // Is more than one repetition allowed?
                    //log("MULTIPLE REPS: MIN:"+toString(prod.items[1]) + "  MAX:"+toString(prod.items[2])+"  :"+stringifyParsePos(parsePos))
                    parsePos.append(PCItm)
                      if(constructParseMap(prod2TimesUsed, parsePos, level+1)){parsePos.popLast(); return(true)}
                    parsePos.popLast()
                }
              //  parsePos.popLast()
            } else if(prod.prodType==parseALT){
                withEach p in prod.items{
                    parsePos.last().index <+- prod.items.size()
                    me productionChainItem: PCItm; PCItm.prodID <- p;  PCItm.index <- 0;
                    parsePos.append(PCItm)
                      if(constructParseMap(prod2TimesUsed, parsePos, level+1)){parsePos.popLast(); return(true)}
                    parsePos.popLast()
                }
            } else {logFatalError("Unexpected productionType:"+toString(prod.prodType))}
        }
        return(false)
    }


    void: tryToFindAmbiguities() <- {
        log("=================================================== Search for ambiguities")
        me Map<me int, me int>: prod2TimesUsed
        me List<productionChainItem>: parsePos
        me productionChainItem: PCItm; PCItm.prodID <- infon_str;  PCItm.index <- 0;
        parsePos.append(PCItm)
        constructParseMap(prod2TimesUsed, parsePos, 0)
        //withEach prod in prod2TimesUsed{log(toString(prod_key)+"-PROD:"+grammar[prod_key].nameToStr(rnames)+ ": times used:"+toString(prod2TimesUsed[prod_key]) + "  lvlsToBackApprove:"+toString(grammar[prod_key].lvlsToBackApprove))}
    }
*/
    void: dump() <- {
        withEach crntPos in RANGE(0 .. SSets.size()) {
            their stateSets: SSet <- SSets[crntPos]
            me string: ch <- "x"
            if(crntPos+1 != SSets.size()) {
                ch <- streamToParse.atSafe(crntPos)
            }
            me string: logStr <- ""; me int64: tmp <- crntPos
            logStr <+- "SLOT: "+ toString(tmp)+"'"+ ch+ "' - size:\n"
            withEach SRec in SSet.stateRecs {
                logStr <+- SRec.mySymbol()+": "
                logStr <+- SRec.pedigrees[0].pred.mySymbol()+": "
                logStr <+- SRec.pedigrees[0].cause.mySymbol()+":"
                logStr <+- "    "+SRec.stringify(self)+"\n"
            }
            log(logStr)
        }
        if(parseFound){
            log("\nPARSE PASSED!")
            //log("lastTopLevelItem:"+lastTopLevelItem.mySymbol()+"")
        }
        else {log("\nPARSE failed.\n")}
    }

    void: addSRecToGrapher(our stateRec: SRec) <-{
        me string: sRecSym <- SRec.mySymbol()
        me string: attrs <-""
        if(SRec.MARKer1){attrs<-"style=filled fillcolor=yellow"}
        if(SRec.MARKer2){attrs<-"style=filled fillcolor=lightblue"}
        if(SRec.MARKer1 and SRec.MARKer2){attrs<-"style=filled fillcolor=green"}
        if(SRec===lastTopLevelItem){attrs<-"style=filled fillcolor=blue"}
        if(SRec===topParseNode){attrs<-"style=filled fillcolor=purple"}
        if(SRec.failed){attrs<-"style=filled fillcolor=orange"}
        if(SRec.parseDone){attrs<-"style=filled fillcolor=brown"}
        grapher.addNode(sRecSym, SRec.stringify(self)+":"+SRec.mySymbol(), attrs)
    }

    void: dumpGraph(me string: title, me int: layout) <- {
        grapher.clear()
        grapher.addItem("rankdir=LR;")
        me Map<me string, me string>: rankSlots
        me string: prevHeader <- ""
        withEach crntPos in RANGE(0 .. SSets.size()) {
            me int64: curPos <- crntPos
            their stateSets: SSet <- SSets[crntPos]
            me string: ch <- "x"
            if(crntPos+1 != SSets.size()) {
                ch <- streamToParse.atSafe(crntPos)
            }
            if(layout==0){
                me string: slotLabel <- "SLOT: "+ toString(curPos)+"'"+ ch +"'"
                grapher.addNode(slotLabel, "", "shape=box")
                rankSlots[toString(curPos)] <+- "\""+slotLabel+"\"; "
                if(prevHeader!=""){grapher.addArrow(prevHeader, slotLabel, "", "")}
                prevHeader <- slotLabel
            }
            withEach SRec in SSet.stateRecs {
                if(SRec.next==NULL and SRec.child==NULL){continue()}
                //if(SRec.pedigrees.isEmpty()){continue()}
                me string: sRecSym <- SRec.mySymbol()
                me string: rankID
                if(layout==0){rankID <- toString(curPos)}
                else if(layout==1){rankID <- toString(SRec.originPos)+":"+toString(SRec.productionID)}
                rankSlots[rankID] <+- "\""+sRecSym+"\"; "
                addSRecToGrapher(SRec)
                if(SRec.next!=NULL){
                    grapher.addArrow(sRecSym, SRec.next.mySymbol(), "next", "color=orange")
                    if(SRec.next.next==NULL){
                        addSRecToGrapher(SRec.next)
                        rankSlots[rankID] <+- "\""+SRec.next.mySymbol()+"\"; "
                    }
                }
                if(SRec.child!=NULL){
                    addSRecToGrapher(SRec.child)
                    grapher.addArrow(sRecSym, SRec.child.mySymbol(), "child", "color=brown")
                }
               // if(SRec.buCause!=NULL){grapher.addArrow(sRecSym, SRec.buCause.mySymbol(), "buCause", "color=blue")}
                me int: count<-0
                withEach ped in SRec.pedigrees{
                    me string: cntStr <- ""
                    if(count>0){cntStr<-toString(count)}
                    if(ped.pred!=NULL){
              //          grapher.addArrow(sRecSym, ped.pred.mySymbol(), "pred"+cntStr, "color=green")
                    }
                    if(ped.cause!=NULL){
              //          grapher.addArrow(sRecSym, ped.cause.mySymbol(), "cause"+cntStr, "color=darkgreen")
                    }
                    count <+- 1
                }
            }
            withEach rankItem in rankSlots{
                me string: sameRank <- "{rank=same; " + rankItem + "}"
                grapher.addItem(sameRank)
            }
        }
        me string: filename <- grapher.deQuote(title)+".dot"
        grapher.saveGraph(title, filename) ; grapher.clear()
    }

    void: dumpResolvePath(our stateRec: SRec) <- {
        me int: curPos <- SRec.crntPos
        me string: sRecSym <- SRec.mySymbol()
        me string: ch <- streamToParse.atSafe(curPos)
        addSRecToGrapher(SRec)
        me int: count<-0
        withEach ped in SRec.pedigrees{
            me string: cntStr <- ""
            if(count>0){cntStr<-toString(count)}
            if(ped.pred!=NULL){
                if(ped.pred.crntPos!=curPos){
                    grapher.addArrow(sRecSym, ped.pred.mySymbol(), "pred"+cntStr, "color=darkgreen")
                    dumpResolvePath(ped.pred)
                }
            }
            if(ped.cause!=NULL){
                me string: pedCauseSym <- ped.cause.mySymbol()
                grapher.addArrow(sRecSym, pedCauseSym, "cause"+cntStr, "color=orange")
                addSRecToGrapher(ped.cause)
            }
            count <+- 1
        }
    }

    void: dumpParseTrace(me string: title, me int: charPos) <-{
        grapher.clear()
        grapher.addItem("rankdir=LR;")
        me int: curPos <- charPos
        their stateSets: SSet <- SSets[charPos]
        withEach SRec in SSet.stateRecs {
            dumpResolvePath(SRec)
        }

        me string: filename <- grapher.deQuote(title)+".dot"
        grapher.saveGraph(title, filename) ; grapher.clear()
    }

    void: topOffSSets() <- {
        me int64: sizeDiff <- (streamToParse.size()+1) - SSets.size()
        if(sizeDiff>0){
            me stateSets: newSSet
            withEach i in RANGE(0 .. sizeDiff){
                SSets.append(newSSet)
            }
        }
    }

    me int64: chkStr(me int64: pos, me string: s) <- {
        me int64: L <- s.size()
        our strBufItr: txtItr <- getItrAt(pos)
        withEach i in RANGE(0 .. L){
            if(txtItr == NULL or txtItr.status!=bfOK or txtItr.ch() != s[i]){return(-1)}
            txtItr.goNext()
        }
        return(L)
    }
    me int64: scrapeUntil(me int64: pos, me string:endStr) <- {
        me char: ender <- endStr[0]
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(ch==ender){
                me int64: p <- txtItr.crntAbsPos()
                me int64: nxtLen <- chkStr(p, endStr)
                if(nxtLen>0){return((p+nxtLen)-pos)}
            }
            txtItr.goNext()
        }
        return(-1)
    }
    me int64: escapedScrapeUntil(me int:pos, me string:endChar) <- {
        me string: prevCharStr <- " "
        me char: prevChar <- prevCharStr[0]
        me char: ender <- endChar[0]
        me string: escCharStr <- "\\ "
        me char: escChar <- escCharStr[0]
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            me int64: p <- txtItr.crntAbsPos()
            if(prevChar!=escChar and ch==ender){return(p-pos)}
            if(prevChar==escChar and ch==escChar) {prevChar<-escCharStr[1]}
            else {prevChar <- ch}
            txtItr.goNext()
        }
        return(-1)
    }
    me int64: scrapeUTF8Char(me int64: pos, their int32: out) <- {
        our strBufItr: txtItr <- getItrAt(pos)
        me int: count <- 0
        me int: expectedBytes <- -1
        me string: bufr <- ""
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(count==0){
                expectedBytes <- remainingOctets(ch) + 1
            }
            bufr <+- ch
            count <+- 1
            if(count==expectedBytes){break()}
            txtItr.goNext()
        }
        if(count!=expectedBytes){return(-1)}
        me int64: p<-0
        packUTF8Char(bufr, p, out)
        return(expectedBytes)
    }
    me int64: scrapeAlphaSeq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isalpha(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeUintSeq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isdigit(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeHexNum(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isxdigit(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeBinNum(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isxdigit(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeAlphaNumSeq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isalnum(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeFlexNum(me int64: pos) <- {
        me int64: charsUsed <- 0
        me bool: sepCharFound <- false  // '.' or '/' was found.
        our strBufItr: txtItr <- getItrAt(pos)
        if(txtItr.ch()=="." or txtItr.ch()=="/"){return(-1)}
        me char: prevCH <- " "
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!(isdigit(ch) or ((ch=="." or ch=="/") and !sepCharFound))){
                if(charsUsed==0){return(-1)}
                else{
                    if(prevCH!="." and prevCH!="/"){return(charsUsed)}
                    else{return(-1)}
                }
            }
            if(ch=="." or ch=="/"){sepCharFound <- true}
            prevCH <- ch
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeAlphaNum_Seq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if (!(isalnum(ch) or ch=="_")){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }

    me int64: scrapeUnicodeWordContinue(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me int32: ch
            me int: bytesUsed <- scrapeUTF8Char(pos, ch)
            if(charsUsed==0 and bytesUsed<=0){return(-1)}
            if (!(unicodeMgr.isUnicodeWordContinue(ch))){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            pos <+- bytesUsed
            txtItr.goNext()
            charsUsed <+- bytesUsed
        }
        if(charsUsed==0){return(-1)}
        return(charsUsed)
    }
    me int64: scrapePrintableSeq(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isprint(ch)){
                if(charsUsed==0){return(-1)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeCComment(me int:pos) <- {
        me char: ch <- getCharAt(pos)
        if(ch=="/"){
            me char: nextCh <- getCharAt(pos+1)
            if(nextCh=="/"){
                return(scrapeToEOL(pos))
            } else if(nextCh=="*"){
                return(scrapeUntil(pos+2, "*/")+2)
            }
        }
        return(0)
    }
    me int64: scrapeWSC(me int64: pos) <- {
        me int64: charsUsed <- 0
        me int64: p <- pos
        while(true){
            me int64: prevP <- p
            me char: ch <- getCharAt(p)
            if(isspace(ch)){p <+- 1; charsUsed <+- 1}
            else if(ch=="/"){
                me int64: cmntLen <- scrapeCComment(p)
                if(cmntLen>0){p <+- cmntLen; charsUsed <+- cmntLen}
            }
            if(prevP == p){  // !WSC(ch)
                if(charsUsed==0){return(0)}
                else{return(charsUsed)}
            }
        }
        return(0) // Never reached
    }
    me int64: scrapeWS(me int64: pos) <- {
        me int64: charsUsed <- 0
        our strBufItr: txtItr <- getItrAt(pos)
        while(txtItr != NULL and txtItr.status==bfOK){
            me char: ch <- txtItr.ch()
            if(!isspace(ch)){
                if(charsUsed==0){return(0)}
                else{return(charsUsed)}
            }
            txtItr.goNext()
            charsUsed <+- 1
        }
        return(charsUsed)
    }
    me int64: scrapeQuotedStr(me int64: pos) <- {
        me string: ch <- ""
        ch <+- getCharAt(pos)
        if(ch != "\'" and ch != "\""){return(-1)}
        else{pos <+- 1}
        me int64: sLen <- escapedScrapeUntil(pos, ch)
        if(sLen<0){return(-1)}
        return(sLen+2)
    }
    me int64: scrapeQuotedStr1(me int64: pos) <- {
        if(chkStr(pos, "'")>=0){pos <- pos+1}else{return(-1)}
        me int64: sLen <- escapedScrapeUntil(pos, "'")
        if(sLen<0){return(-1)}
        return(sLen+2)
    }
    me int64: scrapeQuotedStr2(me int64: pos) <- {
        if(chkStr(pos, "\"")>=0){pos <- pos+1}else{return(-1)}
        me int64: sLen <- escapedScrapeUntil(pos, "\"")
        if(sLen<0){return(-1)}
        return(sLen+2)
    }
    me int64: scrapeCID(me int64: pos) <- {
        me char: ch <- getCharAt(pos)
        if(isalpha(ch)){
            return(scrapeAlphaNum_Seq(pos))
        }
        return(-1)
    }
    me int64: scrapeUniID(me int64: pos) <- {
        me int32: ch
        me int: bytesUsed <- scrapeUTF8Char(pos, ch)
        if(bytesUsed<=0){return(-1)}
        me int: tmpCh <- ch
     //    log("UNICODESTR:'"+toString(bytesUsed) +"  val:"+toString(tmpCh))
        if(unicodeMgr.isUnicodeWordStart(ch)){
            me int64: charsUsed <- scrapeUnicodeWordContinue(pos+bytesUsed)
            if(charsUsed==-1){charsUsed<-0}
            me string:TXT
            withEach idx in RANGE(pos..pos+charsUsed+bytesUsed){
                me char: tChr <- getCharAt(idx)
                TXT <+- tChr
            }
            //~ log("scrapeUniID A:"+TXT+": "+toString(charsUsed+bytesUsed)+" bytesUsed:"+toString(bytesUsed))
            if(charsUsed<0){return(1)}
            else{return(charsUsed+bytesUsed)}
        }
        return(-1)
    }
    me int64: scrapeIntSeq(me int64: pos) <- {
        me int64: initialChars <- 0
        me char: ch <- getCharAt(pos)
        if(ch=="+" or ch=="-"){initialChars <- 1}
        me int64: numDigits <- scrapeUintSeq(pos+initialChars)
        if(numDigits>0){return(numDigits+initialChars)}
        return(-1)
    }
    // TODO: me int64: scrapeRdxSeq(me int64: pos) <- { }
    me int64: scrapeToEOL(me int64: pos) <- {
        return(scrapeUntil(pos, "\\n"))
    }
    me int64: textMatches(me int: ProdID, me int64: pos) <- {
        their production: Prod <- grammar[ProdID]
 //       print('    MATCHING "%s`Prod->constStr.data()`"... ')
        me int: prodType <- Prod.prodType
        if(prodType==parseSEQ){ //prod is simple text match
            return(chkStr(pos, Prod.constStr))
        } else{
            if(prodType==parseAUTO){
                switch(ProdID){
                    case alphaSeq:    {return(scrapeAlphaSeq(pos))}
                    case uintSeq:     {return(scrapeUintSeq(pos))}
                    case FlexNum:     {return(scrapeFlexNum(pos))}
                    case alphaNumSeq: {return(scrapeAlphaNumSeq(pos))}
                    case printables:  {return(scrapePrintableSeq(pos))}
                    case ws:          {return(scrapeWS(pos))}
                    case wsc:         {return(scrapeWSC(pos))}
                    case quotedStr:   {return(scrapeQuotedStr(pos))}
                    case quotedStr1:  {return(scrapeQuotedStr1(pos))}
                    case quotedStr2:  {return(scrapeQuotedStr2(pos))}
                    case HexNum_str:  {return(scrapeHexNum(pos))}
                    case BinNum_str:  {return(scrapeBinNum(pos))}
                    case BigInt:      {return(scrapeUintSeq(pos))}
                    case CID:         {return(scrapeCID(pos))}
                    case UniID:       {return(scrapeUniID(pos))}
                    case intSeq:      {return(scrapeIntSeq(pos))}
             //     case RdxSeq:      {return(scrapeRdxSeq(pos))}
                    case toEOL:       {return(scrapeToEOL(pos))}
                    default: {print("Invalid AUTO-parse production type.\n")}
                }
            }
        }
        return(-1)
    }

    our stateRec: addProductionToStateSet(me int64: crntPos, me int: productionID, me int64: seqPos, me int64: origin, our stateRec: pred, our stateRec: cause) <- {
        me bool: Duplicate <- false
        our stateRec: newStateRecPtr
        their production: prod <- grammar[productionID]
        me int: ProdType <- prod.prodType
        if(crntPos > highestSlotSoFar){highestSlotSoFar <- crntPos}
        withEach item in SSets[crntPos].stateRecs { // Don't add duplicates.
            // TODO: change this to be faster. Not a linear search.
            if(item.productionID==productionID and item.originPos==origin){
                if(item.SeqPosition==seqPos){
                    item.pedigrees.append(pedigree(pred, cause, productionID))
                    newStateRecPtr <- item
                    Duplicate <- true
                }
            }
        }

        if(!Duplicate){
            if(ProdType == parseSEQ or ProdType == parseREP or ProdType == parseALT or ProdType == parseAUTO){
                Allocate(newStateRecPtr, productionID, seqPos, origin, crntPos)
                //log("ALLOC:"+newStateRecPtr.mySymbol() + ": "+newStateRecPtr.stringify(self))
                newStateRecPtr.pedigrees.append(pedigree(pred, cause, productionID))
                if(productionID==startProduction and origin==0) {lastTopLevelItem <- newStateRecPtr}
                //log("  AddToCol:"+toString(crntPos)+" cause:"+cause.mySymbol()+" pred:"+ pred.mySymbol()+": "+newStateRecPtr.mySymbol() + ": "+newStateRecPtr.stringify(self))
                SSets[crntPos].stateRecs.append(newStateRecPtr)
                if(!doQuickParse){applyPartialCompletion(newStateRecPtr)}
            }
        }
        return(newStateRecPtr)
    }

    ///////////////// Late Completion Code
    //  This code handles the case where productions are added with the same origin (crntPos) as their (null) predecessor and must have completions applied from past completions.
    me List<our stateRec>: SRecsToComplete
    me int64: crntPos

    void: resetCompletions(me int64: CrntPos) <- {
        SRecsToComplete.clear()
        crntPos <- CrntPos
    }

    void: registerCompletion(our stateRec: SRecToComplete) <- {
        SRecsToComplete.append(SRecToComplete)
    }

    void: setSRecNextTo(our stateRec: from, our stateRec: next, me string: callLoc) <- {
        //log(callLoc + "SET_NEXT of:"+from.stringify(self)+":"+from.mySymbol() +"  to:"+next.mySymbol())
        me MutexMngr: MtxMgr{streamingSRecNextMutex}
        from.next <- next
        from.nextIsFilled<-true
        streamingSRecNextLock.notifyOne()
    }

    void: setSRecChildTo(our stateRec: from, our stateRec: child, me string: callLoc) <- {
        //log(callLoc + "SET_CHILD of:"+from.stringify(self)+":"+from.mySymbol() +"  to:"+child.mySymbol())
        me MutexMngr: MtxMgr{streamingSRecChildMutex}
        from.child <- child
        from.childIsFilled<-true
        streamingSRecChildLock.notifyOne()
    }
    me bool: predIsNotChosen(our stateRec: SRec) <- {
        our stateRec: pred <- chosenPed(SRec).pred
        if(pred!=NULL and pred.pathNotChosen){
            return(true)
        }
        return(false)
    }
    our stateRec: advanceCompletion(our stateRec: SRec, our stateRec: backSRec) <- {
        if(predIsNotChosen(SRec)){return(NULL)}
        our stateRec: newItem <- NULL
        me int: backSRecProductionID <- backSRec.productionID
        me int64: backSRecOriginPos  <- backSRec.originPos
        me int64: backSRecSeqPos     <- backSRec.SeqPosition
        their production: backProd   <- grammar[backSRec.productionID]
        me int: prodTypeFlag         <- backProd.prodType
        if(prodTypeFlag==parseREP){
            me int: MAX_ITEMS  <- backProd.items[2]
            if((backSRecSeqPos < MAX_ITEMS or MAX_ITEMS==0) and backProd.items[0] == SRec.productionID ){//log(" ADVANCING REP: ")
                newItem <- addProductionToStateSet(crntPos, backSRecProductionID, backSRecSeqPos+1, backSRecOriginPos, backSRec, NULL)
            }
        } else if(prodTypeFlag==parseSEQ){
            if(backSRecSeqPos < backProd.items.size() and backProd.items[backSRecSeqPos] == SRec.productionID){//log(" ADVANCING SEQ: "+SRec.mySymbol())
                newItem <- addProductionToStateSet(crntPos, backSRecProductionID, backSRecSeqPos+1, backSRecOriginPos, backSRec, NULL)
            }
        } else if(prodTypeFlag==parseALT){
            if(backSRecSeqPos == 0){
                withEach backAltProdID in backProd.items {
                    if(backAltProdID==SRec.productionID){//log(" ADVANCING ALT: ")
                        return(addProductionToStateSet(crntPos, backSRecProductionID, backSRecSeqPos+1, backSRecOriginPos, backSRec, NULL))
                    }
                }
            }
        }
        return(newItem)
    }

    void: applyPartialCompletion(our stateRec: backSRec) <- {
        withEach SRec in SRecsToComplete{
            if(SRec.originPos==crntPos and !(backSRec.productionID==SRec.productionID and backSRec.SeqPosition==SRec.SeqPosition and backSRec.originPos==SRec.originPos)){
                our stateRec: newSRec <- advanceCompletion(SRec, backSRec)
            }
        }
    }

    void: complete(our stateRec: SRec, me int64: crntPos) <- {
        me int: productionID <- SRec.productionID
        me int64: originPos  <- SRec.originPos

        if(productionID==startProduction and originPos==0){parseFound <- true}

        if(!doQuickParse){registerCompletion(SRec)}
        their stateSets: SSet  <- SSets[originPos]
        withEach backSRec in SSet.stateRecs {
            if(!(crntPos==originPos and backSRec.productionID==productionID and backSRec.SeqPosition==SRec.SeqPosition and backSRec.originPos==originPos)){
                our stateRec: newSRec <- advanceCompletion(SRec, backSRec)
            }
        }

        if(ruleIsDone(SRec)){ // or grammar[SRec.productionID].prodType==parseREP){
            SRec.MARKer2<-true
            bottomUpResolve(SRec, grammar[productionID].lvlsToBackApprove, "C ")
            if(SRec.child!=NULL and grammar[SRec.child.productionID].prodType==parseREP){
                closeRepStateRec(SRec.child)
            }
        }
    }

    me bool: ruleIsDone(our stateRec: SRec)<-{
        their production: prod <- grammar[SRec.productionID]
        me int: ProdType       <- prod.prodType
        me bool: isTerminal    <- prod.isTerm != 0
        me int64: seqPos       <- SRec.SeqPosition
        if(isTerminal and seqPos==1) {return(true)}
        if(!isTerminal){
            if(ProdType==parseSEQ and seqPos==prod.items.size()) {return(true)}
            if(ProdType==parseALT and seqPos>=1) {return(true)}
            if(ProdType==parseREP and seqPos>=prod.items[1]) {return(true)}
        }
        return(false)
    }

    void: notifyFailure(our stateRec: failed, me string: indent) <- {
        their production: prod <- grammar[failed.productionID]
        me int: ProdType <- prod.prodType
        //log(indent+" FAIL:"+failed.mySymbol()+" : "+failed.stringify(self))
        if(ProdType==parseREP) {
            failed.failed <- true
            me int64: numItems <- failed.SeqPosition
            our stateRec: nextItem <- failed
            our stateRec: topItem  <- nextItem
            while(nextItem){
                //log("NEXT_ITEM_R:"+nextItem.mySymbol())
                nextItem <- chosenPed(nextItem).pred
                if(nextItem){topItem<-nextItem}
            }
            topItem.parseDone<-true
            if(numItems < prod.items[1]){
                failed <- topItem
            } else {
                our stateRec: myCause <- chosenPed(topItem).cause
                if(myCause){
                    setPredsNext(myCause, "notify")
                }
                return()
            }
        }else if(ProdType==parseSEQ){
            failed.failed <- true
            our stateRec: nextItem <- failed
            our stateRec: topItem  <- nextItem
            while(nextItem){
                //log("NEXT_ITEM_S:"+nextItem.mySymbol())
                nextItem <- chosenPed(nextItem).pred
                if(nextItem){
                    if(nextItem.next!=NULL){ // only continue if everything above is 'done'
                        topItem<-nextItem
                    } else {return()}
                }
            }
            failed <- topItem
            //log(indent+" FAIL-2:"+failed.mySymbol()+" : "+failed.stringify(self))
            failed.failed <- true
        }

        withEach ped in failed.pedigrees {
            our stateRec: cause <- ped.cause
            if(cause){
                if(prod.isTerm){
                    failed.failed <- true
                    notifyFailure(cause, indent+"T   ")
                } else {
                    me int: ProdType <- prod.prodType
                    if(ProdType==parseSEQ){
                        notifyFailure(cause, indent+"S   ")
                    }else if(ProdType==parseALT) {
                        failed.altCount <+- 1
                        if(failed.altCount >= prod.items.size()){
                            failed.failed <- true
                            notifyFailure(cause, indent+"A   ")
                        }
                    }else if(ProdType==parseREP) {
                        notifyFailure(cause, indent+"R   ")
                    }
                }
            }else{log(indent+"NO_CAUSE")}
        }
    }

    our stateRec: addRepItemToStateSet(our stateRec: SRec, me int64: crntPos, their production: prod) <- {
        our stateRec: newItm <- NULL
        me int64: seqPos <- SRec.SeqPosition
        me int: MIN_ITEMS <- prod.items[1]
        me int: MAX_ITEMS <- prod.items[2]
        me bool: must_be   <- seqPos < MIN_ITEMS
        me bool: cannot_be <- seqPos > MAX_ITEMS and (MAX_ITEMS!=0)
        if(!must_be){ // COMPLETER for REPetitions
            complete(SRec, crntPos)
            newItm <- addProductionToStateSet(crntPos, prod.items[0], 0, crntPos, NULL, SRec) // Tentative
        } else if(!cannot_be){ // PREDICTOR for REPetitions
            newItm <- addProductionToStateSet(crntPos, prod.items[0], 0, crntPos, NULL, SRec)
        }
        return(newItm)
    }

    void: doParse() <- {
        parseFound <- false
        me int64: crntPos <- 0
        streamToParse.at(crntPos) // Wait for buffer to fill
        while(crntPos<SSets.size()){
            their stateSets: SSet <- SSets[crntPos]

            //log("%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   PROCESSING SLOT: " + toString(crntPos)+ " '" + streamToParse.atSafe(crntPos)+"'")
            resetCompletions(crntPos)
            withEach SRec in SSet.stateRecs {
                their production: prod <- grammar[SRec.productionID]
                me int: ProdType       <- prod.prodType
                me bool: isTerminal    <- prod.isTerm != 0
                me int64: seqPos       <- SRec.SeqPosition
                our stateRec: newItm
                //log("PARSE:" + SRec.mySymbol()+": "+SRec.stringify(self))
                if(ruleIsDone(SRec) and ProdType!=parseREP){ // COMPLETER for non-REPetitions
                    complete(SRec, crntPos)
                }else{
                    if(isTerminal){ // SCANNER: Scanning means Testing for a Matching terminal
                        me int64: len <- textMatches(SRec.productionID, crntPos)
                        if(len>=0){ // if match succeeded
                            newItm <- addProductionToStateSet(crntPos+len, SRec.productionID, 1, crntPos, SRec, NULL)
                        } else {notifyFailure(SRec, ">")}
                    }else{ // non-terminal
                        if(ProdType == parseREP){
                            newItm <- addRepItemToStateSet(SRec, crntPos, prod)
                        } else if(ProdType==parseSEQ){ // Init a SEQ (PREDICTOR)
                            me int: prodID <- prod.items[seqPos]
                            newItm <- addProductionToStateSet(crntPos, prodID, 0, crntPos, NULL, SRec)
                        } else if(ProdType==parseALT){ // Init an ALT (PREDICTOR)
                            withEach AltProd in prod.items {
                                newItm <- addProductionToStateSet(crntPos, AltProd, 0, crntPos, NULL, SRec)
                                //log("ADDED_ALT:"+newItm.stringify(self)+":"+newItm.mySymbol())
                            }
                        }
                    }
                }
            }
       //     log("GRAPHING after Slot:"+toString(crntPos)); dumpGraph("ProcessingSlot"+toString(crntPos), 1)
//withEach SRecI in SSet.stateRecs {log("    SLOT:" + SRecI.mySymbol()+": "+SRecI.stringify(self))} log("#############################")
            crntPos <+- 1
        }
        parseTreeFinished <- true
        //log("GRAPHING after Slot:"+toString(crntPos)); dumpGraph("ProcessingSlot"+toString(crntPos), 1)
    }

    me bool: doesParseHaveError() <- {
        //log("\n\nChecking for Parse Errors...\n")
        errorMesg <- ""
        me int64: lastSSetIDX <- SSets.size()
        me int64: lastPosWithItems <- 0
        withEach ssetIDX in Backward RANGE(0 .. lastSSetIDX){
            their stateSets: SSet <- SSets[ssetIDX]
            me int64: numItems <- SSet.stateRecs.size()
            //me int64: sidx <- ssetIDX; log("Position "+ toString(sidx)+ " has "+ toString(numItems)+ "items.\n")
            if(numItems>0 and lastPosWithItems==0){lastPosWithItems <- ssetIDX; break()}

        }
        //log("lastPosWithItems:"+ toString(lastPosWithItems)+ "\n")

        their stateSets: lastSSet <- SSets[lastPosWithItems]

        me int64: lastSRecIDX <- lastSSet.stateRecs.size()-1
        our stateRec: lastSRec // <- lastSSet.stateRecs[lastSRecIDX]
        their production: prod
        me int: ProdType <- 0
        me int: isTerminal<- 0
        me int64: seqPos<- 0

        withEach SRec in lastSSet.stateRecs {
            lastSRec <- SRec
            prod <- grammar[SRec.productionID]
            ProdType <- prod.prodType
            isTerminal <- prod.isTerm
            seqPos <- SRec.SeqPosition
            if (SRec.productionID==startProduction and SRec.originPos==0 and ((lastPosWithItems+1)==lastSSetIDX) and seqPos==prod.items.size()){
 //               print("Passed\n")  // !!!!!!!!!!!!!!!!!!! This tells when the parse passes.
                return(false)
            }
        }
        if(isTerminal!=0){
            if(seqPos==0){
                me string: errLocation <- streamToParse.getLocationAtCharPos(lastPosWithItems)
                errorMesg <- errLocation+ " ERROR: Expected '" + prod.constStr + "'."
            }
        }

        if(errorMesg=="" and (lastPosWithItems+1)!=lastSSetIDX){
            me string: errLocation <- streamToParse.getLocationAtCharPos(lastPosWithItems)
            errorMesg <- errLocation+ " ERROR: Parse failed for unknown reason."
        }
        if(errorMesg=="") {return(false)}
        else {return(true)}
    }

    void: closeRepStateRec(our stateRec: SRec) <- {
        our stateRec: crnt <- SRec
        while(crnt!=NULL){
            if(crnt.next==NULL){
                setSRecNextTo(crnt, NULL, "CLOSEREP:")
            }
            crnt<-crnt.next
        }
    }

    me int: choosePedigreeToFollow(me int: prodID, their List<me pedigree>: peds) <- {
        return(0)
    }

    their pedigree: chosenPed(our stateRec: SRec) <- {
        return(SRec.pedigrees[choosePedigreeToFollow(SRec.productionID, SRec.pedigrees)])
    }

    our stateRec: setPredsNext(our stateRec: SRec, me string: indent) <- {
        our stateRec: pred <- chosenPed(SRec).pred
        if(pred!=NULL){
        //log("########### setPredsNext:"+pred.stringify(self))
           // if(pred.next==NULL){
                setSRecNextTo(pred, SRec, indent+"R   ")
                if(pred.child!=NULL and grammar[pred.child.productionID].prodType==parseREP){
                    closeRepStateRec(pred.child)
                }
           // }
        }
        return(pred)
    }

    our stateRec: bottomUpResolve(our stateRec: SRec, me int: level, me string: indent) <- {
        if(level<=0){return(NULL)}
        //log(indent+"RESOLVE:"+SRec.stringify(self) + "  LEVEL:"+toString(level))
//if(!SRec.childIsFilled){return(NULL)}
        our stateRec: crntRec <- SRec
        our stateRec: lastSRec <- NULL
        while(crntRec!=NULL){
            lastSRec <- crntRec
            crntRec <- setPredsNext(crntRec, indent+"-A  ")
        }
        if(lastSRec!=NULL){  // TODO: Try not recursing if already done
            me int: count <- 0
            withEach ped in lastSRec.pedigrees {
                our stateRec: cause <- ped.cause
   // log("COUNT:"+toString(count))
  //  if(lastSRec.mySymbol()=="stateRec170" and count==0){count<+-1; log("SKIPPING:"+cause.mySymbol()); cause.pathNotChosen<-true; dumpGraph("Skipping", 1) continue()}
                if(cause){
                    setSRecChildTo(cause, lastSRec, indent +"r   ")
                    if(lastSRec.parseDone){
                        setPredsNext(cause, indent+"cause: ") // only do if lastSRec is totally done, no more reps.
                    }
                    if(level==1){
                        if(lastSRec.child!=NULL and grammar[lastSRec.productionID].prodType==parseREP){cause.MARKer1<-true
                            //log("REP_RESOLVE):"+lastSRec.mySymbol()+"  cause:"+cause.mySymbol())
                            bottomUpResolve(cause, 2, indent+"|x  ") // TODO: This makes redundant calls. Improve it
                        }
                    }else {bottomUpResolve(cause, level-1, indent+"|   ")}
                }
                count <+- 1
            }
        }
        //sleep(100) // test with this, extractionComplete, tell Bruce if it breaks
        SRec.resolved <- true
        return(NULL)
    }

//TODO: Fix topDownResolve()
    our stateRec: topDownResolve(our stateRec: SRec, me string: indent) <- {
        log("TopDownParser broken for now"); exit(2)
        if(SRec == NULL){print("\nStateRecPtr is null.\n\n") exit(1)}
        our stateRec: crntRec <- SRec
        me int64: seqPos <- crntRec.SeqPosition
        me int: prodID <- crntRec.productionID
        their production: Prod <- grammar[prodID]
        if(Prod.isTerm){
           // log(indent+"RES: RESOLVE-TERM:"+crntRec.stringify(self) + " SYM:" + crntRec.mySymbol())
            if(crntRec.pedigrees.size()>0){
                me pedigree: ped <- crntRec.pedigrees[0]
                our stateRec: pedSR <- ped.pred
               // if(pedSR!=NULL){log(indent+"       ped.pred:"+pedSR.stringify(self) + " SYM:" + pedSR.mySymbol())}
                pedSR <- ped.cause
              //  if(pedSR!=NULL){log(indent+"       ped.cause:"+pedSR.stringify(self) + " SYM:" + pedSR.mySymbol())}
            } else{log("NO_PED")}



        } else if(seqPos>0){
            withEach subItem in Backward RANGE(0..seqPos){
                me int: pedToFollow <- choosePedigreeToFollow(prodID, crntRec.pedigrees)
                me pedigree: ped <- crntRec.pedigrees[pedToFollow]
                if(ped.pred.next==NULL){
                  //  set_SRecNextTo(ped.pred, crntRec, "")
          //          log(indent+"RES: SET_NEXT of "+ped.pred.mySymbol()+" to "+crntRec.mySymbol())
                }

                if(!crntRec.resolved){
                    if(ped.cause != NULL){
                        crntRec.child <- topDownResolve(ped.cause, indent+"|    ")
         //               log(indent+"RES: SET_CHILD of "+crntRec.mySymbol()+" to "+crntRec.child.mySymbol() + "   CAUSE:"+ped.cause.mySymbol())
                        if(crntRec.next==NULL){crntRec.nextIsFilled<-true crntRec.MARKer1 <- true}
                    }
                }
                crntRec <- ped.pred
            }
        }
   //     sleep(100)  //TODO: Test streaming mode with this uncommented
        SRec.resolved <- true
        return(crntRec)
    }

    void: docPos(me int: indent, our stateRec: SRec, me string: tag) <- {
        withEach i in RANGE(0 .. indent){ print("|    ")}
        if(SRec){
            print(SRec.stringify(self))
        } else {print(" NULL ")}
        print("  \t", tag, "\n")
    }

    void: displayParse(our stateRec: SRec, me string: indent) <- {
        their production: prod <- grammar[SRec.productionID]
        if(prod.isTerm){
            print(indent, "'")
            withEach i in RANGE(SRec.originPos .. SRec.crntPos){
                print(streamToParse.at(i))
            }
            print("'\n")
        } else {
           // print(indent) SRec.stringify(self) print("\n")
            if(SRec.child){
                displayParse(SRec.child, indent+"   | ")
            }
            if(SRec.next){
                displayParse(SRec.next, indent)
            }
        }
    }

    me string: makeStr(our stateRec: SRec) <- {
        me string: S <- ""
        if(SRec==NULL){return(S)}
        me int64: startPos <- SRec.originPos
        me int64: endPos <- SRec.crntPos
        me int: prod <- SRec.productionID
        if(prod == quotedStr or prod == quotedStr1 or prod == quotedStr2){
            startPos <- startPos+1
            endPos <- endPos-1
        }
        our strBufItr: txtItr <- streamToParse.getItrAt(startPos)
        while(txtItr != NULL and txtItr.status==bfOK and txtItr.crntAbsPos()<endPos){
            me char: ch <- txtItr.ch()
            S <- S+ch
            txtItr.goNext()
        }
        return(S)
    }
    me int64: makeInt(our stateRec: SRec) <- {
        me string: S <- makeStr(SRec)
        me int64: N <- stol(S)
        return(N)
    }
    me BigInt: makeHexInt(our stateRec: SRec) <- {
        me string: S <- makeStr(SRec)
        me BigInt: N
        N.hexNumToBigInt(S)
        return(N)
    }
    me BigInt: makeBinInt(our stateRec: SRec) <- {
        me string: S <- makeStr(SRec)
        me BigInt: N
        N.binNumToBigInt(S)
        return(N)
    }
    our stateRec: getChildStateRec(our stateRec: SRec) <- {
        if(SRec==NULL){return(NULL)}
        if(streamingMode){
            me MutexMngr: MtxMgr{streamingSRecChildMutex}
            while(SRec.child==NULL and !SRec.childIsFilled){
                //log("WAIT(GetChildStateRec) for:"+SRec.stringify(self) + " SYM:" + SRec.mySymbol())
                streamingSRecChildLock.wait(MtxMgr)
                //log("DONE_WAITING?(GetChildStateRec)")
            }
        }
      //  if(SRec.child){if(SRec.next==NULL and !(grammar[SRec.child.productionID].prodType==parseREP)){return(NULL)}}
        //if(SRec.child){log("GetSR_CHILD:"+SRec.stringify(self)+"  "+SRec.mySymbol()  +  "  .CHILD:"+SRec.child.stringify(self)+"  "+SRec.child.mySymbol());}else{log("GetSR_CHILD: NULL")}
        return(SRec.child)
    }

    our stateRec: getNextStateRec(our stateRec: SRec) <- {
        if(streamingMode){
            me MutexMngr: MtxMgr{streamingSRecNextMutex}
            while(SRec.next==NULL and !SRec.nextIsFilled and !parseTreeFinished){
                //log("WAIT(GetNExtStateRec) for:"+SRec.stringify(self) + " SYM:" + SRec.mySymbol())
                streamingSRecNextLock.wait(MtxMgr)
                //log("DONE_WAITING?(GetNExtStateRec)")
            }
        }
        //if(SRec.next){log("GetSR_NEXT:"+SRec.stringify(self)+"  "+SRec.mySymbol()  +  "  .NEXT:"+SRec.next.stringify(self)+"  "+SRec.next.mySymbol());}else{log("GetSR_NEXT: NULL")}
        return(SRec.next)
    }

    our stateRec: initParseFromStream(me int: startProd, their strBuf: streamBuffer) <- {
        parseTreeFinished <- false
        streamToParse <- streamBuffer
        startProduction <- startProd
        highestSlotSoFar<- 0
        SSets.clear()
        topOffSSets()
        lastTopLevelItem <- NULL
        errorMesg <- ""
        resetCompletions(0)
        topParseNode <- addProductionToStateSet(0, startProduction, 0, 0, NULL, NULL)
        return(topParseNode)
    }

    our stateRec: initParseFromString( me string: streamName, me int: startProd, me string: txt) <- {
        // print('Will parse "', txt, '" with rule ', startProd, '.\n')
        their strBuf:: bufToParse
        bufToParse.init(streamName)
        bufToParse.putStr(txt)
        bufToParse.close()
        our stateRec: topParseNode <- initParseFromStream(startProd, bufToParse)
        return(topParseNode)
    }
    void: setStreamingMode(me bool: streamMode) <- {streamingMode <- streamMode}
}
